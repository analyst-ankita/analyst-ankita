{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-10-01T06:17:38.232519Z","iopub.execute_input":"2023-10-01T06:17:38.232966Z","iopub.status.idle":"2023-10-01T06:17:38.247028Z","shell.execute_reply.started":"2023-10-01T06:17:38.232933Z","shell.execute_reply":"2023-10-01T06:17:38.246270Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Project Title: Enhancing Profit Margins for Superstore\n   Introduction: In my capacity as a data analyst with expertise in Python, SQL, and data visualization tools like Tableau, I'm embarking on a mission to enhance profit margins for the Superstore dataset in BigQuery. This project is an opportunity to harness data-driven insights to drive profitability. The primary aim is to identify actionable strategies that can substantially boost Superstore's profitability.\nProject Outline:\n   #### 1. Data Exploration and Understanding:\n•\tCommencing with a thorough exploration of the Superstore dataset, I'll delve into its structure, features, and data quality.\n•\tMy goal is to uncover historical sales and profit trends to lay a solid foundation for the analysis.\n   #### 2. Customer Segmentation:\n•\tLeveraging RFM analysis, I intend to segment customers based on their purchasing behavior.\n•\tThe objective here is to evaluate the profitability of each customer segment, allowing me to prioritize those with the highest profit potential.\n   #### 3. Product Analysis:\n•\tI will scrutinize product categories and sub-categories to distinguish high-margin and low-margin products.\n•\tThe aim is to pinpoint products that exert the most significant influence on profit and sales.\n   #### 4. Pricing Strategy Optimization:\n•\tMy analysis will encompass an examination of the impact of discounts on profit margins and sales.\n•\tSubsequently, I will formulate recommendations for optimal pricing strategies tailored to different product categories.\n   #### 5. Supply Chain and Inventory Management:\n•\tTo optimize profitability, I will assess inventory turnover rates and identify products with slow-moving inventory.\n•\tStrategies for improved inventory management will be proposed to reduce costs and minimize stockouts.\n   #### 6. Geographical Analysis:\n•\tGeographical insights will be derived by analyzing sales and profit patterns across regions, cities, and states.\n•\tThe objective is to identify regions with untapped growth potential and opportunities for cost reduction.\n   #### 7. Data Visualization:\n•\tUtilizing my proficiency in Tableau, I'll craft compelling visualizations that effectively communicate key findings.\n   #### 8. Recommendations and Action Plan:\n•\tSummarizing critical insights, I'll provide a concrete action plan to enhance profit margins.\n•\tMy recommendations will be actionable and aligned with the Superstore's overarching goals\n","metadata":{}},{"cell_type":"code","source":"!pip install xlrd","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-10-01T06:17:38.248876Z","iopub.execute_input":"2023-10-01T06:17:38.249622Z","iopub.status.idle":"2023-10-01T06:17:48.172638Z","shell.execute_reply.started":"2023-10-01T06:17:38.249594Z","shell.execute_reply":"2023-10-01T06:17:48.171324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport pandasql as ps\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go","metadata":{"execution":{"iopub.status.busy":"2023-10-01T06:17:48.176500Z","iopub.execute_input":"2023-10-01T06:17:48.176856Z","iopub.status.idle":"2023-10-01T06:17:48.182893Z","shell.execute_reply.started":"2023-10-01T06:17:48.176828Z","shell.execute_reply":"2023-10-01T06:17:48.181731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Overview of the Dataset: \n   ### The code starts by loading the dataset from an Excel file using the Pandas library and then displays the first 10 rows to provide an overview of the data.","metadata":{}},{"cell_type":"code","source":"# Load your dataset from an Excel file into a pandas DataFrame\n\ndata = pd.read_excel('/kaggle/input/eu-superstore-data/Superstore.xls', sheet_name='Orders', engine='xlrd')","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-10-01T06:17:48.184432Z","iopub.execute_input":"2023-10-01T06:17:48.184703Z","iopub.status.idle":"2023-10-01T06:17:48.782913Z","shell.execute_reply.started":"2023-10-01T06:17:48.184679Z","shell.execute_reply":"2023-10-01T06:17:48.781710Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SQL Query 1 - Overview of the Dataset\nquery1 = \"\"\"\nSELECT *\nFROM data\nLIMIT 10;\n\"\"\"\nresult1 = ps.sqldf(query1, locals())\n\nprint(\"Query 1 - Overview of the Dataset\\n\")\n\nresult1","metadata":{"execution":{"iopub.status.busy":"2023-10-01T06:17:48.786538Z","iopub.execute_input":"2023-10-01T06:17:48.786867Z","iopub.status.idle":"2023-10-01T06:17:49.078590Z","shell.execute_reply.started":"2023-10-01T06:17:48.786830Z","shell.execute_reply":"2023-10-01T06:17:49.077627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Quality Checks:\n*    ### Query 2 checks for missing values in various columns.\n*    ### Query 3 identifies rows with negative values in sales, quantity, discount, or profit.\n*    ### Rows with negative values are replaced with their absolute values.","metadata":{}},{"cell_type":"code","source":"# SQL Query 2 - Data Quality Check - Missing Values\nquery2 = \"\"\"\nSELECT\n  COUNT(*) AS total_rows,\n  SUM(CASE WHEN \"Order ID\" IS NULL THEN 1 ELSE 0 END) AS missing_order_id,\n  SUM(CASE WHEN \"Order Date\" IS NULL THEN 1 ELSE 0 END) AS missing_order_date,\n  SUM(CASE WHEN \"Ship Date\" IS NULL THEN 1 ELSE 0 END) AS missing_ship_date,\n  SUM(CASE WHEN \"Ship Mode\" IS NULL THEN 1 ELSE 0 END) AS missing_ship_mode,\n  SUM(CASE WHEN \"Customer ID\" IS NULL THEN 1 ELSE 0 END) AS missing_customer_id,\n  SUM(CASE WHEN \"Customer Name\" IS NULL THEN 1 ELSE 0 END) AS missing_customer_name,\n  SUM(CASE WHEN \"Segment\" IS NULL THEN 1 ELSE 0 END) AS missing_segment,\n  SUM(CASE WHEN \"City\" IS NULL THEN 1 ELSE 0 END) AS missing_city,\n  SUM(CASE WHEN \"State\" IS NULL THEN 1 ELSE 0 END) AS missing_state,\n  SUM(CASE WHEN \"Country\" IS NULL THEN 1 ELSE 0 END) AS missing_country,\n  SUM(CASE WHEN \"Region\" IS NULL THEN 1 ELSE 0 END) AS missing_region,\n  SUM(CASE WHEN \"Product ID\" IS NULL THEN 1 ELSE 0 END) AS missing_product_id,\n  SUM(CASE WHEN \"Category\" IS NULL THEN 1 ELSE 0 END) AS missing_category,\n  SUM(CASE WHEN \"Sub-Category\" IS NULL THEN 1 ELSE 0 END) AS missing_sub_category,\n  SUM(CASE WHEN \"Product Name\" IS NULL THEN 1 ELSE 0 END) AS missing_product_name,\n  SUM(CASE WHEN \"Sales\" IS NULL THEN 1 ELSE 0 END) AS missing_sales,\n  SUM(CASE WHEN \"Quantity\" IS NULL THEN 1 ELSE 0 END) AS missing_quantity,\n  SUM(CASE WHEN \"Discount\" IS NULL THEN 1 ELSE 0 END) AS missing_discount,\n  SUM(CASE WHEN \"Profit\" IS NULL THEN 1 ELSE 0 END) AS missing_profit\nFROM data;\n\"\"\"\n\nresult2 = ps.sqldf(query2, locals())\n\nprint(\"\\nQuery 2 - Data Quality Check - Missing Values\\n\")\n\nresult2\n","metadata":{"execution":{"iopub.status.busy":"2023-10-01T06:17:49.079700Z","iopub.execute_input":"2023-10-01T06:17:49.079972Z","iopub.status.idle":"2023-10-01T06:17:49.361209Z","shell.execute_reply.started":"2023-10-01T06:17:49.079948Z","shell.execute_reply":"2023-10-01T06:17:49.360064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Quality Check - Negative Values","metadata":{}},{"cell_type":"code","source":"# SQL Query 3 - Data Quality Check - Negative Values\nquery3 = \"\"\"\nSELECT Sales, Quantity, Discount, Profit\nFROM data\nWHERE Sales < 0 OR Quantity < 0 OR Discount < 0 OR Profit < 0;\n\"\"\"\nresult3 = ps.sqldf(query3, locals())\n\nprint(\"\\nQuery 3 - Data Quality Check - Negative Values\\n\")\n\nresult3","metadata":{"execution":{"iopub.status.busy":"2023-10-01T06:17:49.362908Z","iopub.execute_input":"2023-10-01T06:17:49.363355Z","iopub.status.idle":"2023-10-01T06:17:49.806161Z","shell.execute_reply.started":"2023-10-01T06:17:49.363315Z","shell.execute_reply":"2023-10-01T06:17:49.804968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Replacing Rows with Negative Values","metadata":{}},{"cell_type":"code","source":"# Apply .abs() to columns with potential negative values\ndata['Sales'] = data['Sales'].abs()\ndata['Quantity'] = data['Quantity'].abs()\ndata['Discount'] = data['Discount'].abs()\ndata['Profit'] = data['Profit'].abs()\n\n# Define the path for saving the result after replacing negative values\nresult_path = '/kaggle/working/result_after_replacing_negatives.csv'\n\n# Save the entire cleaned DataFrame to a CSV file\ndata.to_csv(result_path, index=False)\n\ndf = pd.read_csv('/kaggle/working/result_after_replacing_negatives.csv')\n\n# Query for rows with negative values\nquery4 = \"\"\"\nSELECT Sales, Quantity, Discount, Profit\nFROM df\nWHERE Sales < 0 OR Quantity < 0 OR Discount < 0 OR Profit < 0;\n\"\"\"\nresult4 = ps.sqldf(query4, locals())\n\n# Print the result\nresult4","metadata":{"execution":{"iopub.status.busy":"2023-10-01T06:17:49.807789Z","iopub.execute_input":"2023-10-01T06:17:49.808426Z","iopub.status.idle":"2023-10-01T06:17:50.194032Z","shell.execute_reply.started":"2023-10-01T06:17:49.808395Z","shell.execute_reply":"2023-10-01T06:17:50.192794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Summary Statistics: \n   ### Query 5 calculates summary statistics such as the total number of rows, average sales, average profit, maximum sales, maximum profit, minimum sales, and minimum profit.","metadata":{}},{"cell_type":"code","source":"# SQL Query 5 - Summary Statistics\nquery5 = \"\"\"\nSELECT\n  COUNT(*) AS total_rows,\n  AVG(Sales) AS avg_sales,\n  AVG(Profit) AS avg_profit,\n  MAX(Sales) AS max_sales,\n  MAX(Profit) AS max_profit,\n  MIN(Sales) AS min_sales,\n  MIN(Profit) AS min_profit\nFROM df;\n\"\"\"\nresult5 = ps.sqldf(query5, locals())\n\nprint(\"\\nQuery 5 - Summary Statistics\\n\")\n\nresult5","metadata":{"execution":{"iopub.status.busy":"2023-10-01T06:17:50.195690Z","iopub.execute_input":"2023-10-01T06:17:50.196256Z","iopub.status.idle":"2023-10-01T06:17:50.402671Z","shell.execute_reply.started":"2023-10-01T06:17:50.196224Z","shell.execute_reply":"2023-10-01T06:17:50.401532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Customer Segmentation (RFM Analysis):\n\n* ### Query 6 identifies the last order date for each customer.\n* ### Query 7 calculates the total number of orders and total sales for each customer.","metadata":{}},{"cell_type":"code","source":"# SQL Query 6 - Customer Segmentation (RFM Analysis) - last_order_date\nquery6 = \"\"\"\nSELECT\n  \"Customer ID\",\n  \"Customer Name\",\n  MAX(\"Order Date\") AS last_order_date\nFROM df\nGROUP BY \"Customer ID\", \"Customer Name\";\n\"\"\"\nresult6 = ps.sqldf(query6, locals())\n\nprint(\"\\nQuery 6 - Customer Segmentation (RFM Analysis) - last_order_date\\n\")\n\nresult6","metadata":{"execution":{"iopub.status.busy":"2023-10-01T06:17:50.404327Z","iopub.execute_input":"2023-10-01T06:17:50.404762Z","iopub.status.idle":"2023-10-01T06:17:50.614426Z","shell.execute_reply.started":"2023-10-01T06:17:50.404720Z","shell.execute_reply":"2023-10-01T06:17:50.613743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert 'last_order_date' to datetime if it's not already\nresult6['last_order_date'] = pd.to_datetime(result6['last_order_date'])\n\n# Create a new column 'last_order_quarter' by extracting the quarter and year\nresult6['last_order_quarter'] = result6['last_order_date'].dt.to_period('Q')\n\n# Group by last_order_quarter and count customers\nquarterly_customer_count = result6.groupby('last_order_quarter').size()\n\nplt.figure(figsize=(10, 6))\nquarterly_customer_count.plot(kind='bar', color='skyblue')\nplt.xlabel('Last Order Quarter')\nplt.ylabel('Number of Customers')\nplt.title('Customer Count by Last Order Quarter')\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T06:17:50.615811Z","iopub.execute_input":"2023-10-01T06:17:50.616247Z","iopub.status.idle":"2023-10-01T06:17:51.043873Z","shell.execute_reply.started":"2023-10-01T06:17:50.616215Z","shell.execute_reply":"2023-10-01T06:17:51.043164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Customer Segmentation (RFM Analysis) - Frequency and Monetary Value","metadata":{}},{"cell_type":"code","source":"# SQL Query 7 - Customer Segmentation (RFM Analysis) - Frequency and Monetary Value\nquery7 = \"\"\"\nSELECT\n  \"Customer ID\",\n  \"Customer Name\",\n  COUNT(DISTINCT \"Order ID\") AS total_orders,\n  SUM(Sales) AS total_sales\nFROM df\nGROUP BY \"Customer ID\", \"Customer Name\";\n\"\"\"\nresult7 = ps.sqldf(query7, locals())\n\nprint(\"\\nQuery 7 - Customer Segmentation (RFM Analysis) - Frequency and Monetary Value\\n\")\n\nresult7","metadata":{"execution":{"iopub.status.busy":"2023-10-01T06:17:51.044798Z","iopub.execute_input":"2023-10-01T06:17:51.045598Z","iopub.status.idle":"2023-10-01T06:17:51.256520Z","shell.execute_reply.started":"2023-10-01T06:17:51.045570Z","shell.execute_reply":"2023-10-01T06:17:51.255370Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extract data from the result DataFrame\ntotal_orders = result7['total_orders']\ntotal_sales = result7['total_sales']\n\nplt.figure(figsize=(10, 6))\nplt.scatter(total_orders, total_sales, color='skyblue', alpha=0.5)\nplt.xlabel('Total Orders')\nplt.ylabel('Total Sales')\nplt.title('Customer Segmentation: Frequency vs. Monetary Value')\nplt.grid(True)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T06:17:51.260149Z","iopub.execute_input":"2023-10-01T06:17:51.260466Z","iopub.status.idle":"2023-10-01T06:17:51.651784Z","shell.execute_reply.started":"2023-10-01T06:17:51.260439Z","shell.execute_reply":"2023-10-01T06:17:51.650688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Product Analysis:\n\n* ### Query 8 analyzes high-margin products by category and sub-category.\n* ### Query 9 provides sales by category and sub-category.","metadata":{}},{"cell_type":"code","source":"# SQL Query 8 - Product Analysis - High Margin Products\nquery8 = \"\"\"\nSELECT\n  \"Category\",\n  \"Sub-Category\",\n  AVG(Profit) AS avg_profit\nFROM df\nGROUP BY \"Category\", \"Sub-Category\"\nORDER BY avg_profit DESC;\n\"\"\"\nresult8 = ps.sqldf(query8, locals())\n\nprint(\"\\nQuery 8 - Product Analysis - High Margin Products\\n\")\n\nresult8","metadata":{"execution":{"iopub.status.busy":"2023-10-01T06:17:51.653217Z","iopub.execute_input":"2023-10-01T06:17:51.653504Z","iopub.status.idle":"2023-10-01T06:17:51.868907Z","shell.execute_reply.started":"2023-10-01T06:17:51.653479Z","shell.execute_reply":"2023-10-01T06:17:51.867949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extract data from the result DataFrame\ncategories = result8['Category'] + \" - \" + result8['Sub-Category']\navg_profit = result8['avg_profit']\n\nplt.figure(figsize=(12, 6))\nplt.barh(categories, avg_profit, color='skyblue')\nplt.xlabel('Average Profit')\nplt.ylabel('Category - Sub-Category')\nplt.title('Product Analysis: High Margin Products')\nplt.gca().invert_yaxis()  # Invert the y-axis for better readability\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T06:17:51.870456Z","iopub.execute_input":"2023-10-01T06:17:51.871427Z","iopub.status.idle":"2023-10-01T06:17:52.328422Z","shell.execute_reply.started":"2023-10-01T06:17:51.871392Z","shell.execute_reply":"2023-10-01T06:17:52.327204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Data\ncategories = result8['Category']\navg_profit = result8['avg_profit']\n\n# Create a bar plot\nplt.figure(figsize=(10, 6))\nplt.bar(categories, avg_profit, color='skyblue')\nplt.xlabel('Product Category')\nplt.ylabel('Average Profit')\nplt.title('Average Profit by Product Category')\nplt.xticks()\nplt.tight_layout()\n\n# Show the plot\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-10-01T06:17:52.329846Z","iopub.execute_input":"2023-10-01T06:17:52.330254Z","iopub.status.idle":"2023-10-01T06:17:52.626716Z","shell.execute_reply.started":"2023-10-01T06:17:52.330206Z","shell.execute_reply":"2023-10-01T06:17:52.625540Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SQL Query 9 - Sales by Category and Sub-Category\nquery9 = \"\"\"\nSELECT\n  \"Category\",\n  \"Sub-Category\",\n  SUM(Sales) AS total_sales\nFROM df\nGROUP BY \"Category\", \"Sub-Category\"\nORDER BY \"Category\", total_sales DESC;\n\"\"\"\nresult9 = ps.sqldf(query9, locals())\n\nprint(\"\\nQuery 9 - Sales by Category and Sub-Category\\n\")\n\nresult9","metadata":{"execution":{"iopub.status.busy":"2023-10-01T06:17:52.628551Z","iopub.execute_input":"2023-10-01T06:17:52.629077Z","iopub.status.idle":"2023-10-01T06:17:52.979460Z","shell.execute_reply.started":"2023-10-01T06:17:52.629048Z","shell.execute_reply":"2023-10-01T06:17:52.978398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data\ncategories = result9['Category'].unique()\nsubcategories = result9['Sub-Category'].unique()\ntotal_sales = result9['total_sales']\n\n# Create a dictionary to store sales by sub-category for each category\ncategory_sales = {cat: [] for cat in categories}\n\n# Populate the dictionary\nfor cat in categories:\n    for subcat in subcategories:\n        subcat_sales = result9[(result9['Category'] == cat) & (result9['Sub-Category'] == subcat)]['total_sales']\n        if not subcat_sales.empty:\n            category_sales[cat].append(subcat_sales.iloc[0])\n        else:\n            category_sales[cat].append(0)\n\n# Create a stacked bar chart\nplt.figure(figsize=(12, 6))\nbottom = None\nfor cat in categories:\n    plt.barh(subcategories, category_sales[cat], label=cat, left=bottom)\n    bottom = category_sales[cat] if bottom is None else [bottom[i] + category_sales[cat][i] for i in range(len(bottom))]\n\n# Set labels, title, and legend\nplt.xlabel('Total Sales')\nplt.ylabel('Sub-Category')\nplt.title('Total Sales by Category and Sub-Category (Stacked Bar Chart)')\nplt.legend(title='Category')\n\n# Show the plot\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T06:17:52.980820Z","iopub.execute_input":"2023-10-01T06:17:52.981930Z","iopub.status.idle":"2023-10-01T06:17:53.586685Z","shell.execute_reply.started":"2023-10-01T06:17:52.981886Z","shell.execute_reply":"2023-10-01T06:17:53.585568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Time Series Analysis:\n\n   ### Query 10 performs a time series analysis, grouping sales and profit by month and year.","metadata":{}},{"cell_type":"code","source":"# SQL Query 10 - Time Series Analysis\nquery10 = \"\"\"\nSELECT\n  strftime('%Y-%m', \"Order Date\") AS order_month,\n  SUM(Sales) AS total_sales,\n  SUM(Profit) AS total_profit\nFROM df\nGROUP BY order_month\nORDER BY order_month;\n\"\"\"\nresult10 = ps.sqldf(query10, locals())\n\nprint(\"\\nQuery 10 - Time Series Analysis\\n\")\n\nresult10","metadata":{"execution":{"iopub.status.busy":"2023-10-01T06:17:53.588058Z","iopub.execute_input":"2023-10-01T06:17:53.588435Z","iopub.status.idle":"2023-10-01T06:17:53.806354Z","shell.execute_reply.started":"2023-10-01T06:17:53.588405Z","shell.execute_reply":"2023-10-01T06:17:53.805097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data\norder_month = result10['order_month']\ntotal_sales = result10['total_sales']\ntotal_profit = result10['total_profit']\n\n# Create a figure and axis\nplt.figure(figsize=(12, 6))\nax = plt.gca()\n\n# Plot total sales\nax.plot(order_month, total_sales, label='Total Sales', marker='o', color='skyblue')\nax.set_xlabel('Order Month')\nax.set_ylabel('Total Sales')\nax.set_title('Time Series Analysis - Total Sales and Profit Over Time')\n\n# Plot total profit\nax.plot(order_month, total_profit, label='Total Profit', marker='o', color='orange')\n\n# Add legend\nax.legend()\n\n# Rotate x-axis labels for better readability\nplt.xticks(rotation=90)\n\n# Show the plot\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-10-01T06:17:53.807829Z","iopub.execute_input":"2023-10-01T06:17:53.808154Z","iopub.status.idle":"2023-10-01T06:17:54.419505Z","shell.execute_reply.started":"2023-10-01T06:17:53.808126Z","shell.execute_reply":"2023-10-01T06:17:54.418504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Customer Behavior Analysis:\n\n* ### Query 12 analyzes customer behavior by counting the total orders and identifying the last purchase date for each customer.\n* ### Query 13 evaluates customer loyalty based on the total number of orders and total profit for each customer.\n* ### Query 14 lists the top 10 customers by total sales.","metadata":{}},{"cell_type":"code","source":"# SQL Query 12 - Customer Behavior Analysis\nquery12 = \"\"\"\nSELECT\n  \"Customer ID\",\n  \"Customer Name\",\n  COUNT(DISTINCT \"Order ID\") AS total_orders,\n  MAX(\"Order Date\") AS last_purchase_date\nFROM df\nGROUP BY \"Customer ID\",\"Customer Name\"\nORDER BY last_purchase_date DESC;\n\"\"\"\nresult12 = ps.sqldf(query12, locals())\n\nprint(\"\\nQuery 12 - Customer Behavior Analysis\\n\")\n\nresult12","metadata":{"execution":{"iopub.status.busy":"2023-10-01T06:17:54.420901Z","iopub.execute_input":"2023-10-01T06:17:54.421206Z","iopub.status.idle":"2023-10-01T06:17:54.641623Z","shell.execute_reply.started":"2023-10-01T06:17:54.421172Z","shell.execute_reply":"2023-10-01T06:17:54.640196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the bin edges and labels for the three groups\nbin_edges = [0, 6, 11, 16]  \nbin_labels = ['Low Orders (0-5)', 'Medium Orders (6-10)', 'High Orders (11-15)']\n\n\n# Add a new column 'Order Group' to categorize customers\nresult12['Order Group'] = pd.cut(result12['total_orders'], bins=bin_edges, labels=bin_labels, right=False)\n\nresult12.head(3)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-01T06:17:54.643601Z","iopub.execute_input":"2023-10-01T06:17:54.643972Z","iopub.status.idle":"2023-10-01T06:17:54.658357Z","shell.execute_reply.started":"2023-10-01T06:17:54.643941Z","shell.execute_reply":"2023-10-01T06:17:54.657231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Count the number of customers in each group\norder_group_counts = result12['Order Group'].value_counts()\n\n# Create a bar plot\nplt.figure(figsize=(10, 6))\norder_group_counts.plot(kind='bar', color='skyblue')\nplt.xlabel('Order Group')\nplt.ylabel('Number of Customers')\nplt.title('Customer Behavior Analysis by Order Group')\nplt.xticks(rotation=0)  # Remove rotation of x-axis labels\n\n# Annotate the bars with the counts\nfor i, count in enumerate(order_group_counts):\n    plt.text(i, count + 5, str(count), ha='center', va='bottom', fontsize=12)\n\n# Show the plot\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T06:17:54.659618Z","iopub.execute_input":"2023-10-01T06:17:54.659919Z","iopub.status.idle":"2023-10-01T06:17:54.988713Z","shell.execute_reply.started":"2023-10-01T06:17:54.659878Z","shell.execute_reply":"2023-10-01T06:17:54.987676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SQL Query 13 - Customer Loyalty Analysis\nquery13 = \"\"\"\nSELECT\n  \"Customer ID\",\n  \"Customer Name\",\n  COUNT(DISTINCT \"Order ID\") AS total_orders,\n  SUM(Profit) AS total_profit\nFROM df\nGROUP BY \"Customer ID\", \"Customer Name\"\nORDER BY total_profit DESC\nLIMIT 15;\n\"\"\"\nresult13 = ps.sqldf(query13, locals())\n\nprint(\"\\nQuery 13 - Customer Loyalty Analysis\\n\")\n\nresult13","metadata":{"execution":{"iopub.status.busy":"2023-10-01T06:17:54.990199Z","iopub.execute_input":"2023-10-01T06:17:54.990489Z","iopub.status.idle":"2023-10-01T06:17:55.200365Z","shell.execute_reply.started":"2023-10-01T06:17:54.990464Z","shell.execute_reply":"2023-10-01T06:17:55.199286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data\ntotal_orders = result13['total_orders']\ntotal_profit = result13['total_profit']\ncustomer_names = result13['Customer Name']\n\n# Create a scatter plot\nplt.figure(figsize=(12, 8))\nplt.scatter(total_orders, total_profit, color='skyblue', alpha=0.5)\nplt.xlabel('Total Orders')\nplt.ylabel('Total Profit')\nplt.title('Customer Loyalty Analysis')\n\n# Add labels for a subset of customer names to avoid overcrowding\nshow_labels = 5  # Change this value to control how many labels you want to display\nfor i in range(show_labels):\n    plt.annotate(customer_names.iloc[i], (total_orders.iloc[i], total_profit.iloc[i]), fontsize=10)\n\n# Show the plot\nplt.grid(True)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T06:17:55.202141Z","iopub.execute_input":"2023-10-01T06:17:55.202451Z","iopub.status.idle":"2023-10-01T06:17:55.637054Z","shell.execute_reply.started":"2023-10-01T06:17:55.202424Z","shell.execute_reply":"2023-10-01T06:17:55.635836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SQL Query 14 - Top N Customers by Sales\nquery14 = \"\"\"\nSELECT\n  \"Customer ID\",\n  \"Customer Name\",\n  SUM(Sales) AS total_sales\nFROM df\nGROUP BY \"Customer ID\", \"Customer Name\"\nORDER BY total_sales DESC\nLIMIT 10;\n\"\"\"\nresult14 = ps.sqldf(query14, locals())\n\nprint(\"\\nQuery 14 - Top N Customers by Sales\\n\")\n\nresult14","metadata":{"execution":{"iopub.status.busy":"2023-10-01T06:17:55.638704Z","iopub.execute_input":"2023-10-01T06:17:55.639210Z","iopub.status.idle":"2023-10-01T06:17:56.002462Z","shell.execute_reply.started":"2023-10-01T06:17:55.639171Z","shell.execute_reply":"2023-10-01T06:17:56.001359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data\ncustomers = result14['Customer Name']\ntotal_sales = result14['total_sales']\n\n# Create a bar plot\nplt.figure(figsize=(10, 6))\nplt.bar(customers, total_sales, color='skyblue')\nplt.xlabel('Customer Name')\nplt.ylabel('Total Sales')\nplt.title('Top N Customers by Sales')\nplt.xticks(rotation=60)\nplt.tight_layout()\n\n# Show the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T06:17:56.003561Z","iopub.execute_input":"2023-10-01T06:17:56.004381Z","iopub.status.idle":"2023-10-01T06:17:56.385104Z","shell.execute_reply.started":"2023-10-01T06:17:56.004348Z","shell.execute_reply":"2023-10-01T06:17:56.384347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Pricing Strategy Optimization\n* ### Query 15 examines the effect of different discount levels on profit margins. It calculates the average profit for each discount percentage and presents the results in ascending order of discount. This analysis can help in making decisions regarding discount strategies and their impact on overall profitability.\n* ### Query 16 focuses on understanding the average discount offered to customers in different segments. It calculates the average discount for each customer segment, which could be useful in tailoring marketing and pricing strategies for specific customer groups.","metadata":{}},{"cell_type":"code","source":"# SQL Query 15 - Impact of Discounts on Profit Margins\nquery15 = \"\"\"\nSELECT\n  \"Discount\",\n  AVG(Profit) AS avg_profit\nFROM df\nGROUP BY \"Discount\"\nORDER BY \"Discount\";\n\"\"\"\nresult15 = ps.sqldf(query15, locals())\n\nprint(\"\\nQuery 15 - Impact of Discounts on Profit Margins\\n\")\n\nresult15","metadata":{"execution":{"iopub.status.busy":"2023-10-01T06:17:56.386093Z","iopub.execute_input":"2023-10-01T06:17:56.386980Z","iopub.status.idle":"2023-10-01T06:17:56.598182Z","shell.execute_reply.started":"2023-10-01T06:17:56.386949Z","shell.execute_reply":"2023-10-01T06:17:56.597087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data\ndiscounts = result15['Discount']\navg_profit = result15['avg_profit']\n\n# Create a line plot\nplt.figure(figsize=(10, 6))\nplt.plot(discounts, avg_profit, marker='o', color='skyblue', linestyle='-')\nplt.xlabel('Discount')\nplt.ylabel('Average Profit')\nplt.title('Impact of Discounts on Profit Margins')\nplt.grid(True)\nplt.tight_layout()\n\n# Show the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T06:17:56.599612Z","iopub.execute_input":"2023-10-01T06:17:56.600869Z","iopub.status.idle":"2023-10-01T06:17:57.004937Z","shell.execute_reply.started":"2023-10-01T06:17:56.600834Z","shell.execute_reply":"2023-10-01T06:17:57.003512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SQL Query 16 - Average Discount by Segment\nquery16 = \"\"\"\nSELECT\n  \"Segment\",\n  AVG(Discount) AS avg_discount\nFROM df\nGROUP BY \"Segment\";\n\"\"\"\nresult16 = ps.sqldf(query16, locals())\n\nprint(\"\\nQuery 16 - Average Discount by Segment\\n\")\n\nresult16","metadata":{"execution":{"iopub.status.busy":"2023-10-01T06:17:57.006272Z","iopub.execute_input":"2023-10-01T06:17:57.006593Z","iopub.status.idle":"2023-10-01T06:17:57.218502Z","shell.execute_reply.started":"2023-10-01T06:17:57.006565Z","shell.execute_reply":"2023-10-01T06:17:57.217579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data\nsegments = result16['Segment']\navg_discounts = result16['avg_discount']\n\n# Create a bar plot\nplt.figure(figsize=(10, 6))\nplt.bar(segments, avg_discounts, color='skyblue')\nplt.xlabel('Segment')\nplt.ylabel('Average Discount')\nplt.title('Average Discount by Segment')\nplt.xticks()\nplt.tight_layout()\n\n# Show the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T06:17:57.219816Z","iopub.execute_input":"2023-10-01T06:17:57.220212Z","iopub.status.idle":"2023-10-01T06:17:57.509394Z","shell.execute_reply.started":"2023-10-01T06:17:57.220184Z","shell.execute_reply":"2023-10-01T06:17:57.508563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Supply Chain and Inventory Management\n* ### Query 17 is related to supply chain and inventory management. It calculates the inventory turnover rate for various products by counting the number of orders and summing the quantity sold for each product. This information is crucial for optimizing inventory levels and ensuring efficient supply chain operations.","metadata":{}},{"cell_type":"code","source":"# SQL Query 17 - Inventory Turnover Rate\nquery17 = \"\"\"\nSELECT\n  \"Product ID\",\n  \"Product Name\",\n  \"Category\",\n  \"Sub-Category\",\n  COUNT(DISTINCT \"Order ID\") AS total_orders,\n  SUM(Quantity) AS total_quantity\nFROM df\nGROUP BY   \"Category\", \"Sub-Category\";\n\"\"\"\nresult17 = ps.sqldf(query17, locals())\n\nprint(\"\\nQuery 17 - Inventory Turnover Rate\\n\")\n\nresult17","metadata":{"execution":{"iopub.status.busy":"2023-10-01T06:19:20.370686Z","iopub.execute_input":"2023-10-01T06:19:20.371083Z","iopub.status.idle":"2023-10-01T06:19:20.592940Z","shell.execute_reply.started":"2023-10-01T06:19:20.371054Z","shell.execute_reply":"2023-10-01T06:19:20.592059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data\ncategories = result17['Category'] + ' - ' + result17['Sub-Category']\ntotal_orders = result17['total_orders']\ntotal_quantity = result17['total_quantity']\n\n# Create a line graph\nplt.figure(figsize=(12, 6))\nplt.plot(categories, total_orders, marker='o', label='Total Orders', color='skyblue')\nplt.plot(categories, total_quantity, marker='o', label='Total Quantity', color='orange')\nplt.xlabel('Category - Sub-Category')\nplt.ylabel('Count')\nplt.title('Total Orders and Total Quantity by Category and Sub-Category')\nplt.xticks(rotation=90)\nplt.legend()\n\n# Show the plot\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T06:25:24.450954Z","iopub.execute_input":"2023-10-01T06:25:24.451401Z","iopub.status.idle":"2023-10-01T06:25:24.903050Z","shell.execute_reply.started":"2023-10-01T06:25:24.451367Z","shell.execute_reply":"2023-10-01T06:25:24.902031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Geographical Analysis\n* ### Query 18 provides insights into sales performance across different regions.\n* ### Query 19 delves into the profitability of product categories and sub-categories in different regions. \n* ### Query 20 analyzes profitability at the state level. It calculates the total profit for each state and ranks them by descending profitability.","metadata":{}},{"cell_type":"code","source":"# SQL Query 18 - Sales by Region\nquery18 = \"\"\"\nSELECT\n  \"Region\",\n  \"Country\",\n  SUM(Sales) AS total_sales\nFROM df\nGROUP BY \"Region\", \"Country\"\nORDER BY total_sales DESC;\n\"\"\"\nresult18 = ps.sqldf(query18, locals())\n\nprint(\"\\nQuery 18 - Sales by Region\\n\")\n\nresult18","metadata":{"execution":{"iopub.status.busy":"2023-10-01T06:25:50.072645Z","iopub.execute_input":"2023-10-01T06:25:50.073842Z","iopub.status.idle":"2023-10-01T06:25:50.286274Z","shell.execute_reply.started":"2023-10-01T06:25:50.073804Z","shell.execute_reply":"2023-10-01T06:25:50.285405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a DataFrame with region, country, and total sales\ndf_map = result18.copy()\n\n# Create a bubble map\nfig = px.scatter_geo(\n    df_map,\n    locations=\"Country\",  # Use \"Country\" as the location field\n    locationmode=\"country names\",  # Specify location mode for country names\n    color=\"Region\",  # Color bubbles by region\n    size=\"total_sales\",  # Size of bubbles represents total sales\n    hover_name=\"Country\",  # Show country name on hover\n    projection=\"natural earth\",  # Choose a map projection\n    title=\"Sales by Region and Country\"\n)\n\n# Customize the map layout\nfig.update_geos(\n    showcoastlines=True, coastlinecolor=\"Black\",\n    showland=True, landcolor=\"lightgray\",\n    showocean=True, oceancolor=\"lightblue\",\n    showcountries=True, countrycolor=\"Black\"\n)\n\n# Show the map\nfig.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-10-01T06:25:55.240077Z","iopub.execute_input":"2023-10-01T06:25:55.240492Z","iopub.status.idle":"2023-10-01T06:25:55.307142Z","shell.execute_reply.started":"2023-10-01T06:25:55.240465Z","shell.execute_reply":"2023-10-01T06:25:55.306054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SQL Query 19 - Profitable Categories and Sub-Categories by Region\nquery19 = \"\"\"\nSELECT\n  \"Region\",\n  \"Category\",\n  \"Sub-Category\",\n  SUM(Profit) AS total_profit\nFROM df\nGROUP BY \"Region\", \"Category\", \"Sub-Category\"\nORDER BY \"Region\", total_profit DESC;\n\"\"\"\nresult19 = ps.sqldf(query19, locals())\n\nprint(\"\\nQuery 19 - Profitable Categories and Sub-Categories by Region\\n\")\n\nresult19","metadata":{"execution":{"iopub.status.busy":"2023-10-01T06:29:00.125793Z","iopub.execute_input":"2023-10-01T06:29:00.126255Z","iopub.status.idle":"2023-10-01T06:29:00.524771Z","shell.execute_reply.started":"2023-10-01T06:29:00.126221Z","shell.execute_reply":"2023-10-01T06:29:00.523636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a DataFrame with region, category, sub-category, and total profit\ndf_treemap = result19.copy()\n\n# Create a treemap\nfig = px.treemap(\n    df_treemap,\n    path=[\"Region\", \"Category\", \"Sub-Category\"],  # Define the hierarchy\n    values=\"total_profit\",  # Values to be represented by the treemap tiles\n    color=\"total_profit\",  # Color tiles by total profit\n    color_continuous_scale=\"Viridis\",  # Choose a color scale\n    title=\"Profitable Categories and Sub-Categories by Region\"\n)\n\n# Show the treemap\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-01T06:29:05.664718Z","iopub.execute_input":"2023-10-01T06:29:05.665103Z","iopub.status.idle":"2023-10-01T06:29:05.786766Z","shell.execute_reply.started":"2023-10-01T06:29:05.665071Z","shell.execute_reply":"2023-10-01T06:29:05.785399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SQL Query 20 - Profitability by State\nquery20 = \"\"\"\nSELECT\n  \"State\",\n  SUM(Profit) AS total_profit\nFROM df\nGROUP BY \"State\"\nORDER BY total_profit DESC;\n\"\"\"\nresult20 = ps.sqldf(query20, locals())\n\nprint(\"\\nQuery 20 - Profitability by State\\n\")\n\n\n\nresult20","metadata":{"execution":{"iopub.status.busy":"2023-10-01T06:29:10.184592Z","iopub.execute_input":"2023-10-01T06:29:10.184954Z","iopub.status.idle":"2023-10-01T06:29:10.397535Z","shell.execute_reply.started":"2023-10-01T06:29:10.184924Z","shell.execute_reply":"2023-10-01T06:29:10.396074Z"},"trusted":true},"execution_count":null,"outputs":[]}]}